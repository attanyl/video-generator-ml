{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the directory containing the images\n",
    "dir_path = './frames'\n",
    "\n",
    "# Loop through all the files in the directory\n",
    "for path in os.listdir(dir_path):\n",
    "    for filename in os.listdir(f'{dir_path}/{path}'):\n",
    "        # Check if the file is an image\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "            img_path = f'{dir_path}/{path}/{filename}'\n",
    "            \n",
    "            # Open the image and resize it to 128 x 128\n",
    "            with Image.open(img_path) as img:\n",
    "                if img.size != (128, 128):\n",
    "                    img = img.resize((128, 128))\n",
    "                    img.save(img_path)\n",
    "                # make sure the image is RGB\n",
    "                if img.mode != 'RGB':\n",
    "                    img = img.convert('RGB')\n",
    "                    img.save(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataset to load the images and labels\n",
    "# the subdirectory names are the labels\n",
    "# for each image, add a random amount of Gaussian noise 10 times, selecting from a range of 0 to 100 time steps\n",
    "# add each noisy image to the dataset with the label of the original image and the noise\n",
    "# Path: diffusionmodel.ipynb\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "class DiffusionDataset(Dataset):\n",
    "    def __init__(self, dir_path, transform=None):\n",
    "        self.dir_path = dir_path\n",
    "        self.transform = transform\n",
    "        self.labels = []\n",
    "        self.noisy_images = []\n",
    "        self.noises = []\n",
    "        self.timesteps = []\n",
    "        \n",
    "        # Loop through all the files in the directory\n",
    "        for path in os.listdir(dir_path):\n",
    "            for filename in os.listdir(f'{dir_path}/{path}'):\n",
    "                # Check if the file is an image\n",
    "                if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "                    img_path = f'{dir_path}/{path}/{filename}'\n",
    "                    \n",
    "                    # Open the image and resize it to 128 x 128\n",
    "                    with Image.open(img_path) as img:\n",
    "                        if self.transform:\n",
    "                            img = self.transform(img)\n",
    "                    \n",
    "                    # add 1 noisy images to the dataset\n",
    "                    for _ in range(1):\n",
    "                        # add a random amount of Gaussian noise\n",
    "                        r = np.random.randint(0, 100)\n",
    "                        noise = torch.randn(img.shape) * r\n",
    "                        noisy_img = img + noise\n",
    "                        self.labels.append(path)\n",
    "                        self.noises.append(noise)\n",
    "                        self.noisy_images.append(noisy_img)\n",
    "                        self.timesteps.append(r)\n",
    "                        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.labels[idx], self.noisy_images[idx], self.noises[idx], self.timesteps[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataset\n",
    "ds = DiffusionDataset('./frames', transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataloader to load the dataset\n",
    "dl = DataLoader(ds, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model to guess the noise added to the image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DiffusionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(128 * 128 * 3 + 768 + 1, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc4 = nn.Linear(256, 128 * 128 * 3)\n",
    "        \n",
    "    def forward(self, img, sentence, timestep):\n",
    "        # use the image, sentence, and timestep to predict the noise\n",
    "        img = img.view(img.size(0), -1)\n",
    "        sentence = sentence.view(sentence.size(0), -1)\n",
    "        timestep = timestep.view(timestep.size(0), -1)\n",
    "        x = torch.cat((img, sentence, timestep), dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        # reshape the noise to 3x128x128\n",
    "        x = x.view(x.size(0), 3, 128, 128)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name C:\\Users\\david/.cache\\torch\\sentence_transformers\\princeton-nlp_sup-simcse-bert-base-uncased. Creating a new one with MEAN pooling.\n"
     ]
    }
   ],
   "source": [
    "embedding_model = SentenceTransformer('princeton-nlp/sup-simcse-bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "857\n"
     ]
    }
   ],
   "source": [
    "print(len(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_17684\\4149663053.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  predicted_noises = model(images, torch.tensor(zero_embeddings), timesteps)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Batch 0, Loss 3405.795654296875\n",
      "Epoch 0, Batch 50, Loss 3827.010009765625\n",
      "Epoch 0, Batch 100, Loss 3254.554443359375\n",
      "Epoch 0, Batch 150, Loss 3499.979736328125\n",
      "Epoch 0, Batch 200, Loss 2647.005126953125\n",
      "Epoch 0, Batch 250, Loss 3147.673583984375\n",
      "Epoch 0, Batch 300, Loss 3179.4765625\n",
      "Epoch 0, Batch 350, Loss 2947.805419921875\n",
      "Epoch 0, Batch 400, Loss 3676.226318359375\n",
      "Epoch 0, Batch 450, Loss 2872.381103515625\n",
      "Epoch 0, Batch 500, Loss 1993.609375\n",
      "Epoch 0, Batch 550, Loss 3204.145751953125\n",
      "Epoch 0, Batch 600, Loss 3143.997314453125\n",
      "Epoch 0, Batch 650, Loss 2125.020751953125\n",
      "Epoch 0, Batch 700, Loss 3083.550537109375\n",
      "Epoch 0, Batch 750, Loss 3410.318359375\n",
      "Epoch 0, Batch 800, Loss 3258.860107421875\n",
      "Epoch 0, Batch 850, Loss 3231.862548828125\n"
     ]
    }
   ],
   "source": [
    "# create a model\n",
    "model = DiffusionModel()\n",
    "\n",
    "# create a loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# create an optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(1):\n",
    "    for i, (labels, images, noises, timesteps) in enumerate(dl):\n",
    "        # get the sentence embeddings\n",
    "        sentences = [label for label in labels]\n",
    "        embeddings = embedding_model.encode(sentences)\n",
    "        zero_embeddings = torch.zeros(embeddings.shape)\n",
    "        \n",
    "        # get the predicted noise\n",
    "        predicted_noises = model(images, torch.tensor(embeddings), timesteps)\n",
    "        # calculate the loss\n",
    "        loss = criterion(predicted_noises, noises)\n",
    "        # backpropagate the loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # get the predicted noise\n",
    "        predicted_noises = model(images, torch.tensor(zero_embeddings), timesteps)\n",
    "        # calculate the loss\n",
    "        loss = criterion(predicted_noises, noises)\n",
    "        # backpropagate the loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print the loss every 10 batches\n",
    "        if i % 50 == 0:\n",
    "            print(f'Epoch {epoch}, Batch {i}, Loss {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute '__array_interface__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m     noise \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m predicted_noise\n\u001b[0;32m     18\u001b[0m \u001b[39m# save the image to a file in ./examples\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[39mwith\u001b[39;00m Image\u001b[39m.\u001b[39;49mfromarray(noise) \u001b[39mas\u001b[39;00m img:\n\u001b[0;32m     20\u001b[0m     img\u001b[39m.\u001b[39msave(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m./examples/\u001b[39m\u001b[39m{\u001b[39;00msentence\u001b[39m}\u001b[39;00m\u001b[39m.jpg\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\david\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\Image.py:2982\u001b[0m, in \u001b[0;36mfromarray\u001b[1;34m(obj, mode)\u001b[0m\n\u001b[0;32m   2943\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfromarray\u001b[39m(obj, mode\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   2944\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2945\u001b[0m \u001b[39m    Creates an image memory from an object exporting the array interface\u001b[39;00m\n\u001b[0;32m   2946\u001b[0m \u001b[39m    (using the buffer protocol).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2980\u001b[0m \u001b[39m    .. versionadded:: 1.1.6\u001b[39;00m\n\u001b[0;32m   2981\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2982\u001b[0m     arr \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m__array_interface__\n\u001b[0;32m   2983\u001b[0m     shape \u001b[39m=\u001b[39m arr[\u001b[39m\"\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   2984\u001b[0m     ndim \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(shape)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute '__array_interface__'"
     ]
    }
   ],
   "source": [
    "# generate random noise\n",
    "noise = torch.randn(3, 128, 128)\n",
    "\n",
    "# get the sentence embeddings for an input sentence\n",
    "sentence = input('Enter a sentence: ')\n",
    "embedding = embedding_model.encode([sentence])\n",
    "\n",
    "for i in range(100):\n",
    "    # the timestep is 100 - i\n",
    "    t = 100 - i\n",
    "    \n",
    "    # get the predicted noise\n",
    "    predicted_noise = model(noise.unsqueeze(0), torch.tensor(embedding), torch.tensor([t]))[0]\n",
    "    \n",
    "    # remove the predicted noise from the image\n",
    "    noise -= predicted_noise\n",
    "    \n",
    "# show noise as an image\n",
    "noise_img = transforms.ToPILImage()(noise)\n",
    "noise_img.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
